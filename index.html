<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8' />
    <meta http-equiv="X-UA-Compatible" content="chrome=1" />
    <meta name="description" content="Vatic Action : An online annotation tool for human action labeling, can be easily deployed on Amazon Mturk." />

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Vatic Action</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/dreamdragon/vatic">View on GitHub</a>

          <h1 id="project_title">Vatic Action</h1>
          <h2 id="project_tagline">An online annotation tool for human action labeling, can be easily deployed on Amazon Mturk.</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/dreamdragon/vatic/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/dreamdragon/vatic/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <p>VATIC-ACTION: Video Annotation Tools for Human Actions, based on VATIC, <a href="http://web.mit.edu/vondrick/vatic/">http://web.mit.edu/vondrick/vatic/</a> </p>

<p>vatic is an online, interactive video annotation tool for computer vision research that crowdsources work to Amazon's Mechanical Turk. Our tool makes it easy to build massive, affordable video data sets. Written in Python + C + Javascript, vatic is free and open-source software.</p>

<p>This document will describe how to install and use VATIC-ACTION. If you want 
to modify VATIC-ACTION, please read DEVELOPERS after reading this document.</p>

<h2>
<a name="-references-" class="anchor" href="#-references-"><span class="octicon octicon-link"></span></a>== REFERENCES ==</h2>

<p>When using our system, please cite:</p>

<pre><code>Weiyu Zhang, Menglong Zhu, Kosta Derpanis, "From Actemes to Action:
A Strongly-supervised Representation for Detailed Action Understanding" 
International Conference on Computer Vision (ICCV). Dec 2013.

Carl Vondrick, Deva Ramanan, Donald Patterson. "Efficiently Scaling Up
Video Annotation with Crowdsourced Marketplaces" European Conference on
Computer Vision (ECCV) Crete, Greece, September, 2010. 
</code></pre>

<h2>
<a name="-installation-" class="anchor" href="#-installation-"><span class="octicon octicon-link"></span></a>== INSTALLATION ==</h2>

<p>Note: VATIC has only been tested on Ubuntu with Apache 2.2 HTTP server and a
MySQL server. This document will describe installation on this platform,
however it should work any operating system and with any server.</p>

<h3>
<a name="----download----" class="anchor" href="#----download----"><span class="octicon octicon-link"></span></a>--- Download ---</h3>

<p>You can download and extract VATIC from our website. Note: do NOT run the 
installer as root. </p>

<pre><code>$ wget http://mit.edu/vondrick/vatic/vatic-install.sh
$ chmod +x vatic-install.sh
$ ./vatic-install.sh
$ cd vatic
</code></pre>

<h3>
<a name="----http-server-configuration----" class="anchor" href="#----http-server-configuration----"><span class="octicon octicon-link"></span></a>--- HTTP Server Configuration ---</h3>

<p>Open the Apache configuration file. On Ubuntu, this file is located at:</p>

<pre><code>/etc/apache2/sites-enabled/000-default
</code></pre>

<p>If you do not use Apache on this computer for any other purpose, replace the
contents of the file with:</p>

<pre><code>WSGIDaemonProcess www-data
WSGIProcessGroup www-data

&lt;VirtualHost *:80&gt;
    ServerName vatic.domain.edu
    DocumentRoot /path/to/vatic/public

    WSGIScriptAlias /server /path/to/vatic/server.py
    CustomLog /var/log/apache2/access.log combined
&lt;/VirtualHost&gt;
</code></pre>

<p>updating ServerName with your domain name, DocumentRoot with the path to
the public directory in VATIC, and WSGIScriptAlias to VATIC's server.py file.</p>

<p>If you do use Apache for other purposes, you will have to setup a new virtual
host with the correct document root and script alias, as shown above.</p>

<p>Make sure you have the mod_headers module enabled:</p>

<pre><code>$ sudo cp /etc/apache2/mods-available/headers.load /etc/apache2/mods-enabled
</code></pre>

<p>After making these changes, restart Apache:</p>

<pre><code>$ sudo apache2ctl graceful
</code></pre>

<h3>
<a name="----sql-server-configuration----" class="anchor" href="#----sql-server-configuration----"><span class="octicon octicon-link"></span></a>--- SQL Server Configuration ---</h3>

<p>We recommend creating a separate database specifically for VATIC:</p>

<pre><code>$ mysql -u root
mysql&gt; create database vatic;
</code></pre>

<p>The next section will automatically create the necessary tables.</p>

<h3>
<a name="----setup----" class="anchor" href="#----setup----"><span class="octicon octicon-link"></span></a>--- Setup ---</h3>

<p>Inside the vatic directory, copy config.py-example to config.py:</p>

<pre><code>$ cp config.py-example config.py
</code></pre>

<p>Then open config.py and make changes to the following variables in order to
configure VATIC:</p>

<pre><code>signature       Amazon Mechanical Turk AWS signature (secret access key)
accesskey       Amazon Mechanical Turk AWS access key (access key ID)
sandbox         If true, put into Mturk sandbox mode. For debugging.
localhost       The local HTTP address: http://vatic.domain.edu/ so it
                matches the ServerName in Apache.
database        Database connection string: for example,
                mysql://user:pass@localhost/vatic
geolocation     API key from ipinfodb.com for geolocation services
</code></pre>

<p>If you do not plan on using VATIC on Mechcanical Turk (offlien mode only), you
can leave the signature and accesskey empty.</p>

<p>After saving results, you can then initialize the database:</p>

<pre><code>$ turkic setup --database
</code></pre>

<p>Note: if you want to reset the database, you can do this with:</p>

<pre><code>$ turkic setup --database --reset
</code></pre>

<p>which will require confirmation to reset in order to prevent data loss.</p>

<p>Finally, you must also allow VATIC to access turkic, a major dependency:</p>

<pre><code>$ turkic setup --public-symlink
</code></pre>

<h2>
<a name="-annotation-" class="anchor" href="#-annotation-"><span class="octicon octicon-link"></span></a>== ANNOTATION ==</h2>

<p>Before you continue, you should verify that the installation was correct. You
can verify this with:</p>

<pre><code>$ turkic status --verify
</code></pre>

<p>If you receive any error messages, it means the installation was not complete
and you should review the previous section. Note: If you do not plan on
using Mechanical Turk, you can safely ignore any errors caused by Mechanical
Turk.</p>

<h3>
<a name="----frame-extraction----" class="anchor" href="#----frame-extraction----"><span class="octicon octicon-link"></span></a>--- Frame Extraction ---</h3>

<p>Our system requires that videos are extracted into JPEG frames. Our tool can 
do this automatically for you:</p>

<pre><code>$ mkdir /path/to/output/directory
$ turkic extract /path/to/video.mp4 /path/to/output/directory
</code></pre>

<p>By default, our tool will resize the frames to fit within a 720x480 rectangle.
We believe this resolution is ideal for online video viewing. You can change 
resolution with options:</p>

<pre><code>$ turkic extract /path/to/video.mp4 /path/to/output/directory
  --width 1000 --height 1000
</code></pre>

<p>or</p>

<pre><code>$ turkic extract /path/to/video.mp4 /path/to/output/directory
  --no-resize
</code></pre>

<p>The tool will maintain aspect ratio in all cases.</p>

<p>Alternatively, if you have already extracted frames, you can use the
formatframes command to format the video into a format that VATIC understands:</p>

<pre><code>$ turkic formatframes /path/to/frames/ /path/to/output/directory
</code></pre>

<p>The above command will read all the images in /path/to/frames and create
hard links (soft copy) in /path/to/output/directory.</p>

<h3>
<a name="----importing-a-video----" class="anchor" href="#----importing-a-video----"><span class="octicon octicon-link"></span></a>--- Importing a Video ---</h3>

<p>After extracting frames, the video can be imported into our tool for 
annotation. The general syntax for this operation is:</p>

<pre><code>$ turkic load identifier /path/to/output/directory Label1 Label2 LabelN
</code></pre>

<p>where identifier is a unique string that you will use to refer to this video,
/path/to/output/directory is the directory of frames, and LabelX are class
labels that you want annotated (e.g., Person, Car, Bicycle). You can have as
many class labels as you wish, but you must have at least one.</p>

<p>When a video is imported, it is broken into small segments typically of only a
few seconds. When all the segments are annotated, the annotations are merged
across segments because each segment overlaps another by a small margin.</p>

<p>The above command specifies all of the required options, but there are many
options available as well. We recommend using these options.</p>

<pre><code>MTurk Options
    --title         The title that MTurk workers see
    --description   The description that MTurk workers see
    --duration      Time in seconds that a worker has to complete the task
    --lifetime      Time in seconds that the task is online
    --keywords      Keywords that MTurk workers can search on
    --offline       Disable MTurk and use for self annotation only

Compensation Options
    --cost                  The price advertised to MTurk workers
    --per-object-bonus      A bonus in dollars paid for each object
    --completion-bonus      A bonus in dollars paid for completing the task

Qualification Options
    --min-approved-percent  Minimum percent of tasks the worker must have
                            approved before they can work for you
    --min-approved-amount   Minimum number of tasks that the worker must 
                            have completed before they can work for you

Video Options
    --length        The length of each segment for this video in frames
    --overlap       The overlap between segments in frames
    --use-frames    When splitting into segments, only the frame intervals
                    specified in this file. Each line should contain a
                    start frame, followed by a space, then the stop frame.
                    Frames outside the intervals in this file will be
                    ignored.
    --skip          If specified, request annotations only every N frames.
    --blow-radius   When a user marks an annotation, blow away all other
                    annotations within this many frames. If you want to
                    allow the user to make fine-grained annotations, set
                    this number to a small integer, or 0 to disable. By
                    default, this is 0.
    --action        action class name 
    --pose          coarse camera view point
</code></pre>

<p>You can also specify temporal attributes that each object label can take on.
For example, you may have a person object with attributes "walking", "running",
or "sitting". You can specify attributes the same way as labels, except you
prepend an ~ before the text, which bind the attribute to the previous label:</p>

<pre><code>$ turkic load identifier /path/to/output/directory Label1 ~Attr1A ~Attr1B
  Label2 ~Attr2A ~Attr2B ~Attr2C Label3 
</code></pre>

<p>In the above example, Label1 will have attributes Attr1A and Attr1B, Label2
will have attributes Attr2B, Attr2B, and Attr2C and Label3 will have no 
attributes. Specifying attributes is optional.</p>

<h3>
<a name="----gold-standard-training----" class="anchor" href="#----gold-standard-training----"><span class="octicon octicon-link"></span></a>--- Gold Standard Training ---</h3>

<p>It turns out that video annotation is extremely challenging and most MTurk
workers lack the necessary patience. For this reason, we recommend requiring
workers to pass a "gold standard" video. When a new worker visits the task,
they will be redirected to a video for which the annotations are already known.
In order to move on to the true annotations, the worker must correctly annotate
the gold standard video first. We have found that this approach significantly
improves the quality of the annotations.</p>

<p>To use this feature, import a video to be used as the gold standard:</p>

<pre><code>$ turkic load identifier-train /path/to/frames Label1 Label2 LabelN
  --for-training --for-training-start 0 --for-training-stop 500
  --for-training-overlap 0.5 --for-training-tolerance 0.1
  --for-training-mistakes 1
</code></pre>

<p>You can also use any of the options described above. Explanations for the new
options are as follows:</p>

<pre><code>--for-training              Specifies that this video is gold standard
--for-training-start        Specifies the first frame to use
--for-training-stop         Specifies the last frame to use
--for-training-overlap      Percent overlap that worker's boxes must match 
--for-training-tolerance    Percent that annotations must agree temporally
--for-training-mistakes     The number of completely wrong annotations 
                            allowed. We recommend setting this to a small,
                            nonzero integer.
</code></pre>

<p>After running the above command, it will provide you with an URL for you to
input the ground truth annotation. You must make this ground truth annotation
as careful as possible, as it will be used to evaluate future workers.</p>

<p>You can now specify that a video should use a gold standard video:</p>

<pre><code>$ turkic load identifier /path/to/output/directory Label1 Label2 LabelN
  --train-with identifier-train
</code></pre>

<p>When a not-yet-seen worker visits this video, they will now be redirected to
to the training video and be required to pass the evaluation test first.</p>

<h3>
<a name="----publishing-tasks----" class="anchor" href="#----publishing-tasks----"><span class="octicon octicon-link"></span></a>--- Publishing Tasks ---</h3>

<p>When you are ready for the MTurk workers to annotate, you must publish the 
tasks, which will allow workers to start annotating:</p>

<pre><code>$ turkic publish
</code></pre>

<p>You can limit the number of tasks that are published:</p>

<pre><code>$ turkic publish --limit 100
</code></pre>

<p>Running above command repeatedly will launch tasks in batches of 100. You can
also disable all pending tasks:</p>

<pre><code>$ turkic publish --disable
</code></pre>

<p>which will "unpublish" tasks that have not yet been completed.</p>

<p>If you have videos that are offline only, you can see their access URLs with
the command:</p>

<pre><code>$ turkic publish --offline
</code></pre>

<p>Note: for the above command to work, you must have loaded the video with the
--offline parameter as well: </p>

<pre><code>$ turkic load identifier /path/to/frames Person --offline
</code></pre>

<h3>
<a name="----checking-the-status----" class="anchor" href="#----checking-the-status----"><span class="octicon octicon-link"></span></a>--- Checking the Status ---</h3>

<p>You can check the status of the video annotation server with the command:</p>

<pre><code>$ turkic status
</code></pre>

<p>This will list various statistics about the server, such as number of jobs
published and how many are completed. You can get even more statistics by
requesting additional information from Amazon:</p>

<pre><code>$ turkic status --turk
</code></pre>

<p>which will output how much money is left in your account, among other
statistics.</p>

<p>When all the videos are annotated, the last line will read:</p>

<pre><code>Server is offline.
</code></pre>

<h3>
<a name="----retrieving-annotations----" class="anchor" href="#----retrieving-annotations----"><span class="octicon octicon-link"></span></a>--- Retrieving Annotations ---</h3>

<p>You can get all the annotations for a video with the command:</p>

<pre><code>$ turkic dump identifier -o output.txt
</code></pre>

<p>which will write the file "output.txt" where each line contains one
annotation. Each line contains 10+ columns, separated by spaces. The
definition of these columns are:</p>

<pre><code>1   Track ID. All rows with the same ID belong to the same path.
2   xmin. The top left x-coordinate of the bounding box.
3   ymin. The top left y-coordinate of the bounding box.
4   xmax. The bottom right x-coordinate of the bounding box.
5   ymax. The bottom right y-coordinate of the bounding box.
6   frame. The frame that this annotation represents.
7   lost. If 1, the annotation is outside of the view screen.
8   occluded. If 1, the annotation is occluded.
9   generated. If 1, the annotation was automatically interpolated.
10  label. The label for this annotation, enclosed in quotation marks.
11+ attributes. Each column after this is an attribute.
</code></pre>

<p>Note: VATIC-ACTION keeps the same xmin,ymin,xmax,ymax as in VATIC for 
consistency purposes. They are computed and stored as a 10x10 pixels 
bounding box around the joint position. For getting the joint position, 
just take the center point of the bounding box.</p>

<p>By default, the above command will not attempt to merge annotations across
shot segments. You can request merging with the command:</p>

<pre><code>$ turkic dump identifier -o output.txt --merge --merge-threshold 0.5
</code></pre>

<p>The --merge-threshold option is optional, but it is a number between 0 and 1
that represents much the paths must agree in order to merge. 1 specifies a
perfect match and 0 specifies no match. In practice, 0.5 is sufficient. Merging
is done using the Hungarian algorithm.</p>

<p>You can also scale annotations by a factor, which is useful for when the
videos have been downsampled:</p>

<pre><code>$ turkic dump identifier -o output.txt -s 2.8
</code></pre>

<p>or force it to fit within a max dimension:</p>

<pre><code>$ turkic dump identifier -o output.txt --dimensions 400x200
</code></pre>

<p>or force it to fit within the dimensions of the original video:</p>

<pre><code>$ turkic dump identifier -o output.txt --original-video /path/to/video.mp4
</code></pre>

<p>The command can also output to many different formats. Available formats are:</p>

<pre><code>--xml       Use XML
--json      Use JSON
--matlab    Use MATLAB
--pickle    Use Python's Pickle
--labelme   Use LabelMe video's XML format
--pascal    Use PASCAL VOC format, treating each frame as an image
</code></pre>

<p>The specifications for these formats should be self explanatory.</p>

<h3>
<a name="----visualizing-videos----" class="anchor" href="#----visualizing-videos----"><span class="octicon octicon-link"></span></a>--- Visualizing Videos ---</h3>

<p>You can preview the annotations by visualizing the results:</p>

<pre><code>$ turkic visualize identifier /tmp --merge
</code></pre>

<p>which will output frames to /tmp with the bounding boxes with the file name
as the frame number. The visualization will contain some meta information
that can help you identify bad workers. You can remove this meta information
with the option:</p>

<pre><code>$ turkic visualize identifer /tmp --merge --no-augment
</code></pre>

<p>If you want to make a video of the visualization (e.g., with ffmpeg), it is
useful to renumber the frames so that they start counting at 0 and do not
have any gaps:</p>

<pre><code>$ turkic visualize identifier /tmp --merge --renumber
</code></pre>

<p>If you wish to display the class label and their attributes next to the box,
specify the --labels option:</p>

<pre><code>$ turkic visualize identifier /tmp --labels
</code></pre>

<h3>
<a name="----compensating-workers----" class="anchor" href="#----compensating-workers----"><span class="octicon octicon-link"></span></a>--- Compensating Workers ---</h3>

<p>When you are ready, you can compensate workers:</p>

<pre><code>$ turkic compensate --default accept
</code></pre>

<p>which will pay all workers for all outstanding tasks. We strongly recommend
paying all workers regardless of their quality. You should attempt to pay
workers at least once per day.</p>

<h3>
<a name="----finding-jobs----" class="anchor" href="#----finding-jobs----"><span class="octicon octicon-link"></span></a>--- Finding Jobs ---</h3>

<p>If you have found a small mistake in a video and want to make
the correction yourself, you can start an annotation session initialized with
the MTurk workers annotations:</p>

<pre><code>$ turkic find --id identifier
$ turkic find --id identifier --frame frame
</code></pre>

<p>where identifier is the identifier for the video and frame is the frame number
that the error occurs. In most cases, this command will return one URL for you
to make the corrections. If it outputs two URLs, it means the frame number
occurs in two overlapping segments, and so you may have to make changes to both
of the segments. You can also omit the frame argument, in which case it will
output all URLs for that video.</p>

<p>If you want to find the HIT id, assignment ID, or worker ID for a particular
video, specify the --ids parameter to the vet command:</p>

<pre><code>$ turkic find --id identifer --ids
$ turkic find --id identifer --frame frame --ids
</code></pre>

<p>will print a list of all the IDs for the video. If the corresponding segment
has been published and completed, it will list three strings: the HIT ID,
assignment ID, and the worker ID. If the job has been published but not
finished, it will just list the HIT ID. If the job has not yet been published,
it prints "(not published)".</p>

<p>Additionally, if you want to find the job that corresponds to a particular
HIT ID, you can use the find command:</p>

<pre><code>$ turkic find --hitid HITID
</code></pre>

<h3>
<a name="----quality-control----" class="anchor" href="#----quality-control----"><span class="octicon octicon-link"></span></a>--- Quality Control ---</h3>

<p>The gold standard does a "pretty good" job of weeding out bad workers.
Nonetheless, there will always be bad workers that we must identify and
invalidate. Our tool provides a method to sample the annotations provided by
workers, which you can then manually verify for correctness:</p>

<pre><code>$ turkic sample /tmp
</code></pre>

<p>which by default will pick 3 random videos that the worker has completed, and
pick 4 random frames from each of those videos, and write visualiations to a
file in /tmp. You can tweak the number of videos and the number of frames with
the options:</p>

<pre><code>$ turkic sample /tmp --number 3 --frames 4
</code></pre>

<p>Moreover, you can only look at work from a certain date:</p>

<pre><code>$ turkic sample /tmp --since "yesterday"
</code></pre>

<p>The filename will follow the format of WORKERID-JOBID.jpg. Once you have
identified a mallicious worker, you can block them, invalidate ALL of their
work, and respawn their jobs with the command:</p>

<pre><code>$ turkic invalidate workerid
</code></pre>

<p>The options are also available:</p>

<pre><code>--no-block      invalidate and respawn, but don't block
--no-publish    block and invalidate, but don't respawn
</code></pre>

<p>You can also invalidate and respawn individual jobs with the command:</p>

<pre><code>$ turkic invalidate --hit hitid
</code></pre>

<h3>
<a name="----listing-all-videos----" class="anchor" href="#----listing-all-videos----"><span class="octicon octicon-link"></span></a>--- Listing all Videos ---</h3>

<p>You can retrieve a list of all videos in the system with:</p>

<pre><code>$ turkic list
</code></pre>

<p>If you want just the videos that have been published:</p>

<pre><code>$ turkic list --published
</code></pre>

<p>If you want just the videos that have been worked on:</p>

<pre><code>$ turkic list --completed
</code></pre>

<p>If you instead want the videos that are used for gold standard:</p>

<pre><code>$ turkic list --training
</code></pre>

<p>Finally, if you just want to count how many videos are in the system, use the
--count option, in combination with any of the above:</p>

<pre><code>$ turkic list --count
$ turkic list --published --count
</code></pre>

<p>If you want statistics about each video, then give the --stats option:</p>

<pre><code>$ turkic list --stats
</code></pre>

<h3>
<a name="----managing-workers----" class="anchor" href="#----managing-workers----"><span class="octicon octicon-link"></span></a>--- Managing Workers ---</h3>

<p>You can list all known workers with the command:</p>

<pre><code>$ turkic workers
</code></pre>

<p>which will dump every worker with the number of jobs they have completed. You
can also use this command to block and unblock workers:</p>

<pre><code>$ turkic workers --block workerid
$ turkic workers --unblock workerid
</code></pre>

<p>You can also search for workers by the first few letters of their ID:</p>

<pre><code>$ turkic workers --search A3M
</code></pre>

<h3>
<a name="----deleting-a-video----" class="anchor" href="#----deleting-a-video----"><span class="octicon octicon-link"></span></a>--- Deleting a Video ---</h3>

<p>You can delete a video at any time with:</p>

<pre><code>$ turkic delete identifier
</code></pre>

<p>If the video has already been annotated (even partially), this command will 
warn you and abort. You can force deletion with:</p>

<pre><code>$ turkic delete identifier --force
</code></pre>

<p>which will REMOVE ALL DATA AND CANNOT BE UNDONE.</p>

<h2>
<a name="-feedback-and-bugs-" class="anchor" href="#-feedback-and-bugs-"><span class="octicon octicon-link"></span></a>== FEEDBACK AND BUGS ==</h2>

<p>Please direct all comments and report all bugs to:</p>

<p>Menglong Zhu <a href="mailto:menglong@cis.upenn.edu">menglong@cis.upenn.edu</a></p>

<p><a href="http://www.seas.upenn.edu/%7Emenglong/">http://www.seas.upenn.edu/~menglong/</a></p>

<p>Thanks for using our system!</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Vatic Action maintained by <a href="https://github.com/dreamdragon">dreamdragon</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
